{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8lZjxv1fDbP",
        "outputId": "6d6b4208-9d8b-410d-b259-2f30fc528e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics roboflow==1.* opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU disponible:\", torch.cuda.is_available())\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYK98fvpfTfa",
        "outputId": "5e667123-4031-4d43-92b1-2fbaa4e4776a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU disponible: True\n",
            "Wed Aug 27 12:28:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8J9CgvKgWtTVxnEYRIuI\")\n",
        "project = rf.workspace(\"computervisionfactoria\").project(\"factoria-f5-citpf\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sfr6-XDgIFj",
        "outputId": "8db77a7f-7442-4367-f539-98afef255b15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Factoria-F5-3 to yolov8:: 100%|██████████| 180842/180842 [00:03<00:00, 55041.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Factoria-F5-3 in yolov8:: 100%|██████████| 4448/4448 [00:00<00:00, 5192.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "data_yaml = os.path.join(dataset.location, \"data.yaml\")\n",
        "model = YOLO(\"yolov8n.pt\")  # empieza con n (nano); luego puedes probar s o m\n",
        "\n",
        "results = model.train(\n",
        "    data=data_yaml,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    device=0,          # <--- 0 = usa la primera GPU\n",
        "    name=\"factoria_f5_gpu\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8YVSQnJgXQp",
        "outputId": "1e3dc569-46e2-47c0-af48-fae226a6eadf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2/6.2MB 78.1MB/s 0.1s\n",
            "Ultralytics 8.3.187 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Factoria-F5-3/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=factoria_f5_gpu, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/factoria_f5_gpu, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1/755.1KB 17.2MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4/5.4MB 75.8MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2103.0±647.5 MB/s, size: 74.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Factoria-F5-3/train/labels... 1938 images, 316 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1938/1938 2513.7it/s 0.8s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Factoria-F5-3/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 54, len(boxes) = 2503. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 958.9±756.4 MB/s, size: 81.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Factoria-F5-3/valid/labels... 135 images, 24 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 135/135 1840.5it/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Factoria-F5-3/valid/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 4, len(boxes) = 168. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/factoria_f5_gpu/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/factoria_f5_gpu\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      2.14G      1.832      4.084      1.559          3        640: 100% ━━━━━━━━━━━━ 122/122 3.3it/s 36.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.5it/s 2.0s\n",
            "                   all        135        168      0.749      0.231      0.256      0.123\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      2.62G      1.812      3.166      1.555          5        640: 100% ━━━━━━━━━━━━ 122/122 3.6it/s 34.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.0it/s 1.2s\n",
            "                   all        135        168      0.595      0.365      0.357      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      2.64G      1.831      2.807      1.587          2        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.6it/s 1.9s\n",
            "                   all        135        168      0.657      0.396      0.404      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      2.65G      1.843      2.519      1.605          4        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s\n",
            "                   all        135        168      0.647      0.473      0.464      0.234\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      2.68G      1.813      2.215      1.584          4        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 32.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.7it/s 1.3s\n",
            "                   all        135        168      0.709      0.535      0.598      0.305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      2.69G      1.779      2.021      1.549          5        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 31.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.9it/s 1.3s\n",
            "                   all        135        168      0.688      0.539      0.526      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      2.71G      1.755       1.95      1.527          3        640: 100% ━━━━━━━━━━━━ 122/122 3.6it/s 33.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.5it/s 2.0s\n",
            "                   all        135        168      0.847      0.536      0.607      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      2.72G       1.72      1.832      1.526          7        640: 100% ━━━━━━━━━━━━ 122/122 3.6it/s 33.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s\n",
            "                   all        135        168       0.74      0.523      0.551      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      2.75G      1.721      1.736      1.497          2        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 32.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.8it/s 1.3s\n",
            "                   all        135        168      0.924      0.567      0.713      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      2.75G      1.676      1.681      1.456          0        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s\n",
            "                   all        135        168      0.685      0.602      0.642      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      2.78G      1.645       1.65      1.459          3        640: 100% ━━━━━━━━━━━━ 122/122 3.6it/s 34.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.7it/s 1.1s\n",
            "                   all        135        168      0.889      0.598      0.708      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      2.79G      1.638      1.513      1.456          3        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.8it/s 1.8s\n",
            "                   all        135        168      0.885      0.598      0.653      0.341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      2.81G      1.623      1.495      1.436          0        640: 100% ━━━━━━━━━━━━ 122/122 3.9it/s 31.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.0it/s 1.3s\n",
            "                   all        135        168      0.654      0.664       0.65      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      2.82G      1.626      1.445      1.449          1        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.0it/s 1.2s\n",
            "                   all        135        168      0.861      0.596      0.666      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      2.85G      1.603       1.44      1.434          3        640: 100% ━━━━━━━━━━━━ 122/122 3.9it/s 31.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.8it/s 1.3s\n",
            "                   all        135        168      0.945       0.62      0.723      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      2.86G      1.581      1.405      1.413          0        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 32.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.0it/s 1.3s\n",
            "                   all        135        168      0.891      0.608      0.676      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      2.88G      1.582       1.38      1.409          1        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 32.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.1it/s 1.6s\n",
            "                   all        135        168      0.843      0.647      0.715      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      2.89G      1.572      1.271      1.401          3        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s\n",
            "                   all        135        168      0.731      0.646      0.689      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      2.92G      1.547      1.284      1.401          3        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 33.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s\n",
            "                   all        135        168      0.898      0.625      0.697      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      2.93G      1.546      1.266      1.382          6        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.9it/s 1.7s\n",
            "                   all        135        168      0.711      0.689      0.702      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      2.95G      1.536      1.233      1.375          3        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 31.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s\n",
            "                   all        135        168      0.742      0.693       0.72      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      2.96G      1.502      1.207      1.357          4        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 32.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s\n",
            "                   all        135        168      0.695      0.674      0.707        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      2.99G      1.483       1.15      1.356          5        640: 100% ━━━━━━━━━━━━ 122/122 3.9it/s 31.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.8it/s 1.3s\n",
            "                   all        135        168      0.732      0.696      0.716      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      2.99G      1.468      1.164      1.327          2        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 5.2it/s 1.0s\n",
            "                   all        135        168      0.918       0.65      0.711       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      3.02G      1.493       1.17      1.346          2        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 32.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.9it/s 1.3s\n",
            "                   all        135        168      0.745      0.707      0.718      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      3.03G      1.489      1.126       1.33          8        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 31.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s\n",
            "                   all        135        168      0.799      0.649      0.714      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      3.06G      1.429      1.132      1.324          9        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 32.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.2it/s 1.2s\n",
            "                   all        135        168       0.72      0.649      0.697      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      3.06G      1.445      1.084      1.318          7        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 31.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        135        168      0.773      0.654      0.731      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      3.09G      1.442      1.045      1.322          1        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.1s\n",
            "                   all        135        168      0.741      0.687      0.713      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50       3.1G      1.417      1.014      1.298          6        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 33.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s\n",
            "                   all        135        168      0.779      0.668      0.716      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      3.12G      1.393      1.039      1.301          6        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s\n",
            "                   all        135        168      0.727      0.688      0.708      0.405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      3.13G      1.385     0.9914      1.285          1        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 33.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s\n",
            "                   all        135        168      0.799      0.685      0.721      0.404\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      3.16G      1.379     0.9924      1.275          0        640: 100% ━━━━━━━━━━━━ 122/122 3.6it/s 34.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.8it/s 1.0s\n",
            "                   all        135        168      0.798      0.685      0.735      0.404\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      3.17G      1.379     0.9814      1.276          7        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 32.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.2it/s 1.2s\n",
            "                   all        135        168      0.837      0.682      0.725      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      3.19G      1.357     0.9736      1.274          3        640: 100% ━━━━━━━━━━━━ 122/122 3.6it/s 34.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.2it/s 1.2s\n",
            "                   all        135        168       0.83      0.684      0.728      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50       3.2G      1.357      0.974      1.275          7        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 33.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.9it/s 1.3s\n",
            "                   all        135        168      0.825      0.682      0.719      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      3.23G      1.359     0.9205      1.267          4        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s\n",
            "                   all        135        168      0.683      0.718      0.722      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      3.23G      1.321     0.9011      1.254          2        640: 100% ━━━━━━━━━━━━ 122/122 3.6it/s 33.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s\n",
            "                   all        135        168      0.783      0.659      0.738      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      3.26G      1.307     0.9236       1.25          4        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 33.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.0it/s 1.7s\n",
            "                   all        135        168      0.804      0.699       0.73       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      3.27G      1.278     0.8925      1.217          3        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s\n",
            "                   all        135        168      0.825      0.685       0.71      0.393\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      3.29G      1.258       0.85      1.224          0        640: 100% ━━━━━━━━━━━━ 122/122 3.7it/s 33.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.0it/s 1.2s\n",
            "                   all        135        168      0.785       0.68      0.726       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50       3.3G      1.227     0.8211      1.224          4        640: 100% ━━━━━━━━━━━━ 122/122 4.0it/s 30.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.0it/s 1.3s\n",
            "                   all        135        168      0.797      0.672      0.714      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      3.33G      1.213     0.7913      1.207          2        640: 100% ━━━━━━━━━━━━ 122/122 3.9it/s 31.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.2it/s 1.2s\n",
            "                   all        135        168       0.81      0.666      0.728       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      3.34G      1.205     0.7991      1.215          5        640: 100% ━━━━━━━━━━━━ 122/122 4.0it/s 30.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s\n",
            "                   all        135        168      0.806      0.669      0.715      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      3.36G      1.192      0.768       1.19          3        640: 100% ━━━━━━━━━━━━ 122/122 3.9it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s\n",
            "                   all        135        168      0.768      0.708      0.724      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      3.37G       1.18     0.7662      1.191          2        640: 100% ━━━━━━━━━━━━ 122/122 4.0it/s 30.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.0it/s 1.3s\n",
            "                   all        135        168      0.798      0.654      0.729      0.404\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50       3.4G      1.162     0.7603      1.167          2        640: 100% ━━━━━━━━━━━━ 122/122 3.9it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s\n",
            "                   all        135        168      0.797      0.666      0.735      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50       3.4G      1.145     0.7379      1.174          3        640: 100% ━━━━━━━━━━━━ 122/122 3.9it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s\n",
            "                   all        135        168      0.787      0.668      0.728      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      3.43G      1.148     0.7322      1.164          6        640: 100% ━━━━━━━━━━━━ 122/122 3.6it/s 34.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s\n",
            "                   all        135        168      0.756       0.69      0.733      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      3.44G      1.121     0.7106      1.147          2        640: 100% ━━━━━━━━━━━━ 122/122 3.8it/s 32.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 5.2it/s 1.0s\n",
            "                   all        135        168      0.726      0.724      0.748      0.424\n",
            "\n",
            "50 epochs completed in 0.475 hours.\n",
            "Optimizer stripped from runs/detect/factoria_f5_gpu/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/factoria_f5_gpu/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/factoria_f5_gpu/weights/best.pt...\n",
            "Ultralytics 8.3.187 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.9it/s 2.7s\n",
            "                   all        135        168      0.727      0.724      0.748      0.423\n",
            "                    F5          7          7      0.249      0.142      0.171     0.0525\n",
            "              Factoria         76         80       0.85      0.875      0.897      0.456\n",
            "             FemCoders         13         14      0.934          1      0.995      0.615\n",
            "      Fundacion Orange         22         31      0.732      0.645      0.675      0.341\n",
            "             Microsoft         10         13      0.779      0.769      0.808       0.56\n",
            "               SomosF5         23         23      0.816      0.913      0.944      0.516\n",
            "Speed: 0.3ms preprocess, 2.9ms inference, 0.1ms loss, 6.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/factoria_f5_gpu\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val(data=data_yaml, split=\"test\", imgsz=640)\n",
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QRgV7A3m9i7",
        "outputId": "36c16a04-68af-4f81-c0a3-12a26b278a02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.187 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1217.4±591.4 MB/s, size: 73.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Factoria-F5-3/test/labels... 145 images, 21 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 145/145 2581.6it/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Factoria-F5-3/test/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3, len(boxes) = 199. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 3.7it/s 2.7s\n",
            "                   all        145        199       0.85       0.73      0.779      0.446\n",
            "                    F5          5          7      0.598      0.286      0.212       0.12\n",
            "              Factoria         89        106      0.977      0.972      0.977      0.529\n",
            "             FemCoders         23         24      0.948          1      0.995      0.628\n",
            "      Fundacion Orange         18         23      0.738       0.49      0.659      0.342\n",
            "             Microsoft         10         12      0.877       0.75      0.888      0.589\n",
            "               SomosF5         27         27       0.96       0.88      0.945      0.469\n",
            "Speed: 2.3ms preprocess, 6.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/factoria_f5_gpu2\u001b[0m\n",
            "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([0, 1, 2, 3, 4, 5])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7c9b073edd90>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.66667,     0.66667,     0.66667, ...,  6.3773e-05,  3.1886e-05,           0],\n",
            "       [          1,           1,           1, ...,    0.015307,   0.0076533,           0],\n",
            "       [          1,           1,           1, ...,           1,           1,           0],\n",
            "       [          1,           1,           1, ...,   0.0011717,  0.00058583,           0],\n",
            "       [          1,           1,           1, ...,        0.16,        0.16,           0],\n",
            "       [          1,           1,           1, ...,     0.15789,     0.15789,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.026667,    0.026667,    0.041268, ...,           0,           0,           0],\n",
            "       [    0.35395,     0.35395,     0.48203, ...,           0,           0,           0],\n",
            "       [    0.40678,     0.40678,     0.54982, ...,           0,           0,           0],\n",
            "       [    0.14035,     0.14035,     0.21536, ...,           0,           0,           0],\n",
            "       [    0.12766,     0.12766,     0.15691, ...,           0,           0,           0],\n",
            "       [    0.23176,     0.23176,     0.34101, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.013652,    0.013652,    0.021407, ...,           1,           1,           1],\n",
            "       [    0.21639,     0.21639,     0.32051, ...,           1,           1,           1],\n",
            "       [    0.25532,     0.25532,     0.37914, ...,           1,           1,           1],\n",
            "       [   0.076336,    0.076336,      0.1229, ...,           1,           1,           1],\n",
            "       [   0.068182,    0.068182,    0.085134, ...,           1,           1,           1],\n",
            "       [    0.13107,     0.13107,     0.20719, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.57143,     0.57143,     0.57143, ...,           0,           0,           0],\n",
            "       [     0.9717,      0.9717,      0.9717, ...,           0,           0,           0],\n",
            "       [          1,           1,           1, ...,           0,           0,           0],\n",
            "       [    0.86957,     0.86957,     0.86957, ...,           0,           0,           0],\n",
            "       [          1,           1,           1, ...,           0,           0,           0],\n",
            "       [          1,           1,     0.96296, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: np.float64(0.4794442391205173)\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.11968,     0.52931,      0.6279,     0.34205,     0.58929,     0.46852])\n",
            "names: {0: 'F5', 1: 'Factoria', 2: 'FemCoders', 3: 'Fundacion Orange', 4: 'Microsoft', 5: 'SomosF5'}\n",
            "nt_per_class: array([  7, 106,  24,  23,  12,  27])\n",
            "nt_per_image: array([ 5, 89, 23, 18, 10, 27])\n",
            "results_dict: {'metrics/precision(B)': 0.8497274826141189, 'metrics/recall(B)': 0.7295635474439252, 'metrics/mAP50(B)': 0.7792984374088867, 'metrics/mAP50-95(B)': 0.44612710597736516, 'fitness': 0.4794442391205173}\n",
            "save_dir: PosixPath('runs/detect/factoria_f5_gpu2')\n",
            "speed: {'preprocess': 2.3339024620672086, 'inference': 6.027626696548646, 'loss': 0.0009121862023738654, 'postprocess': 3.2395388689659237}\n",
            "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
            "task: 'detect'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(\n",
        "    source=os.path.join(dataset.location, \"test\", \"images\"),\n",
        "    conf=0.25,\n",
        "    imgsz=640,\n",
        "    save=True,\n",
        "    project=\"runs/predict\",\n",
        "    name=\"factoria_f5_demo\"\n",
        ")\n",
        "print(\"Resultados guardados en:\", pred[0].save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THgCWkl-m-n0",
        "outputId": "c8d0d4ff-7c44-47be-d333-dc4b82f1e1dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/145 /content/Factoria-F5-3/test/images/1656606217870_jpg.rf.40a9549e59c1e7130025da33ade1564d.jpg: 640x640 (no detections), 7.3ms\n",
            "image 2/145 /content/Factoria-F5-3/test/images/1665735788978_jpg.rf.eb4ec9636103963702fcc9b6e669893e.jpg: 640x640 1 Factoria, 7.3ms\n",
            "image 3/145 /content/Factoria-F5-3/test/images/1665735790387_jpg.rf.3bac271f62285bca1c9f7d4fac764ee1.jpg: 640x640 1 Factoria, 1 FemCoders, 7.3ms\n",
            "image 4/145 /content/Factoria-F5-3/test/images/1667459436404_jpg.rf.cd3276ef287a94fe72f3feff7b13bac9.jpg: 640x640 1 Factoria, 7.3ms\n",
            "image 5/145 /content/Factoria-F5-3/test/images/1737560543054_jpg.rf.6177b185de8a332d0380a55a3cf13ed3.jpg: 640x640 1 Factoria, 1 Fundacion Orange, 1 SomosF5, 7.3ms\n",
            "image 6/145 /content/Factoria-F5-3/test/images/1742225856914_jpg.rf.1de064c1ad7f9d76d7197f85691debd0.jpg: 640x640 1 Factoria, 1 SomosF5, 7.3ms\n",
            "image 7/145 /content/Factoria-F5-3/test/images/225259028_579436796797107_1163772387798740733_n_jpg.rf.1182a103377a2683400ce4b731969f60.jpg: 640x640 1 Factoria, 7.2ms\n",
            "image 8/145 /content/Factoria-F5-3/test/images/346257607_248268824373155_1758269138711392767_n_png.rf.65f16600bb126e9cdeababcc27cf6592.jpg: 640x640 1 Factoria, 7.2ms\n",
            "image 9/145 /content/Factoria-F5-3/test/images/3651090103216010828_jpg.rf.95a744d4d2fa1bca2a671c184738cfb0.jpg: 640x640 1 Factoria, 9.6ms\n",
            "image 10/145 /content/Factoria-F5-3/test/images/3662715108609543669_3662714919320759100_jpg.rf.8b9cf0da2094ef604d2e21da50f21f91.jpg: 640x640 2 Fundacion Oranges, 10.3ms\n",
            "image 11/145 /content/Factoria-F5-3/test/images/3662715108609543669_3662715015563059009_jpg.rf.2e6eab1311b5814ff53612d08b27a508.jpg: 640x640 2 Fundacion Oranges, 7.2ms\n",
            "image 12/145 /content/Factoria-F5-3/test/images/3688088809270135075_jpg.rf.9205118d27471524f1a27a0bef5edfd5.jpg: 640x640 1 Fundacion Orange, 7.2ms\n",
            "image 13/145 /content/Factoria-F5-3/test/images/370569225_971154190757393_2810048185851901379_nlow_jpg.rf.1d9be16a331c8820d97c83b23ddf996c.jpg: 640x640 1 Factoria, 1 SomosF5, 7.3ms\n",
            "image 14/145 /content/Factoria-F5-3/test/images/3707609008762300998_3707608994703004743_jpg.rf.332130d6dd1f97ba5c638f539c8822e4.jpg: 640x640 1 Fundacion Orange, 7.3ms\n",
            "image 15/145 /content/Factoria-F5-3/test/images/387807231_1017975326074720_258340950933220526_n_webplow_jpg.rf.165ac6bdc41489c27bab4c68b212aa33.jpg: 640x640 1 Factoria, 2 FemCoderss, 1 SomosF5, 7.2ms\n",
            "image 16/145 /content/Factoria-F5-3/test/images/420367425_672252171502458_2112678982475608531_n_webplow_jpg.rf.e5a91d8bad63d9b1a92c674f74a3fc05.jpg: 640x640 1 Factoria, 1 SomosF5, 7.3ms\n",
            "image 17/145 /content/Factoria-F5-3/test/images/480962660_1105203158071423_8576628167607642360_n_jpg.rf.e62e70e9f8bf8a63d112fed1360658c3.jpg: 640x640 1 Fundacion Orange, 7.3ms\n",
            "image 18/145 /content/Factoria-F5-3/test/images/481079309_1098098328781906_5050989318839622431_n_jpg.rf.7d1d9e312bea819d25561033b84c1117.jpg: 640x640 1 Fundacion Orange, 7.3ms\n",
            "image 19/145 /content/Factoria-F5-3/test/images/481156854_1095257409065998_5014452079151554765_n_jpg.rf.343fdf4ee802ea617f97c4d00c59c459.jpg: 640x640 1 Fundacion Orange, 7.3ms\n",
            "image 20/145 /content/Factoria-F5-3/test/images/481263300_1099065482018524_3683012300201776899_n_jpg.rf.42d89130f33bc45d14628f5df0d8b512.jpg: 640x640 1 Fundacion Orange, 7.2ms\n",
            "image 21/145 /content/Factoria-F5-3/test/images/483369455_1098981885360217_1120248604125106452_n_jpg.rf.0351f2fef2238bc607c18889808ae839.jpg: 640x640 1 Fundacion Orange, 7.3ms\n",
            "image 22/145 /content/Factoria-F5-3/test/images/483429452_1101164201808652_3080204279157230065_n_jpg.rf.5ab42fdfbd339626646bd4366703b38f.jpg: 640x640 1 Fundacion Orange, 7.3ms\n",
            "image 23/145 /content/Factoria-F5-3/test/images/484454212_1101297941795278_4820028966960129206_n_jpg.rf.01ccf7defd78be5370ad8ecc7ce65d3a.jpg: 640x640 1 Fundacion Orange, 6.4ms\n",
            "image 24/145 /content/Factoria-F5-3/test/images/488941962_28897616989885511_4485280547054166192_n_jpg.rf.a9608a86cb18579e3171869561fe39d1.jpg: 640x640 1 Fundacion Orange, 6.3ms\n",
            "image 25/145 /content/Factoria-F5-3/test/images/496296888_1148160250442380_851340583121468945_n_jpg.rf.a5e7889aad5a606d371852fb48643acb.jpg: 640x640 (no detections), 6.4ms\n",
            "image 26/145 /content/Factoria-F5-3/test/images/Captura-de-pantalla-2025-08-26-113740_jpg.rf.01e42854bd981edee82ef8fc2c670ed3.jpg: 640x640 1 F5, 1 Factoria, 2 FemCoderss, 6.3ms\n",
            "image 27/145 /content/Factoria-F5-3/test/images/Captura-de-pantalla-2025-08-26-113921_jpg.rf.ff6b2637dd6d41576bda953929dc2f58.jpg: 640x640 1 Factoria, 6.3ms\n",
            "image 28/145 /content/Factoria-F5-3/test/images/Captura-de-pantalla-2025-08-26-114648_jpg.rf.387133d8f471a2437f77389b05063caf.jpg: 640x640 1 FemCoders, 6.3ms\n",
            "image 29/145 /content/Factoria-F5-3/test/images/Captura-de-pantalla-2025-08-26-120047_jpg.rf.550997508a5cd6e0af7577df0a11ad02.jpg: 640x640 1 FemCoders, 6.3ms\n",
            "image 30/145 /content/Factoria-F5-3/test/images/Captura-de-pantalla-2025-08-26-123047_jpg.rf.45bec9db0efa6607eeb7183dfa35bd0c.jpg: 640x640 1 Factoria, 1 FemCoders, 6.3ms\n",
            "image 31/145 /content/Factoria-F5-3/test/images/D3IhJHIXkAAZuXc_jpg.rf.82da36341d5801d5ebdb6ef8a03ac0b3.jpg: 640x640 2 Factorias, 6.3ms\n",
            "image 32/145 /content/Factoria-F5-3/test/images/FB_IMG_1756212038633_jpg.rf.532ef6a87f659d9f46621126db2f1987.jpg: 640x640 1 Factoria, 1 FemCoders, 6.3ms\n",
            "image 33/145 /content/Factoria-F5-3/test/images/FB_IMG_1756212064164_jpg.rf.5da2d25ea80f2e20cbe8d0bd7a9f1f7e.jpg: 640x640 6 F5s, 1 Factoria, 1 FemCoders, 6.3ms\n",
            "image 34/145 /content/Factoria-F5-3/test/images/FB_IMG_1756212133755_jpg.rf.5dbb42e6cf1576867372c9a3c7deb334.jpg: 640x640 1 Factoria, 1 FemCoders, 6.3ms\n",
            "image 35/145 /content/Factoria-F5-3/test/images/FB_IMG_1756212152323_jpg.rf.85c5ba26cac2f7071b4b622b30441801.jpg: 640x640 1 Factoria, 1 FemCoders, 6.4ms\n",
            "image 36/145 /content/Factoria-F5-3/test/images/FB_IMG_1756212158704_jpg.rf.8283bf36fee6f093799b2f34106934da.jpg: 640x640 1 Factoria, 1 FemCoders, 6.6ms\n",
            "image 37/145 /content/Factoria-F5-3/test/images/FB_IMG_1756212164395_jpg.rf.69510af16cc4a620e98ac99c01d40e41.jpg: 640x640 1 Factoria, 1 FemCoders, 5.9ms\n",
            "image 38/145 /content/Factoria-F5-3/test/images/FB_IMG_1756212169112_jpg.rf.85eba7d33c7787e989fae059c9ef83a9.jpg: 640x640 1 Factoria, 1 FemCoders, 18.4ms\n",
            "image 39/145 /content/Factoria-F5-3/test/images/FB_IMG_1756212171722_jpg.rf.91b721532ae03407ad72c68416d5f08b.jpg: 640x640 1 Factoria, 1 FemCoders, 23.9ms\n",
            "image 40/145 /content/Factoria-F5-3/test/images/FT_9vjUWQAgKeh-_jpg.rf.febda81487a2a55ce8d7b22c2269b9b3.jpg: 640x640 1 Factoria, 27.9ms\n",
            "image 41/145 /content/Factoria-F5-3/test/images/FWhU0nUWQAAH5BB_jpg.rf.afd1b35850cc735bd0b21cea7550ef7e.jpg: 640x640 2 Factorias, 16.6ms\n",
            "image 42/145 /content/Factoria-F5-3/test/images/FfhpfhYXkAEVrWH_jpg.rf.eb81f3d77f57a8e7c26190a595228582.jpg: 640x640 1 Factoria, 9.3ms\n",
            "image 43/145 /content/Factoria-F5-3/test/images/Fsy3DHtWcAgHSE1_jpg.rf.6df0dd489755b999cf5e8ac749561da0.jpg: 640x640 1 Factoria, 10.5ms\n",
            "image 44/145 /content/Factoria-F5-3/test/images/FuytTYjWYAAmFxC_jpg.rf.e2c65023b1124d09c78060776203e9c3.jpg: 640x640 2 Factorias, 1 Microsoft, 10.5ms\n",
            "image 45/145 /content/Factoria-F5-3/test/images/GRJwZDpWkAA4xD2_jpg.rf.654e46f22da1e5fadae8cea71f044a17.jpg: 640x640 1 Factoria, 11.1ms\n",
            "image 46/145 /content/Factoria-F5-3/test/images/Image_28_jpg.rf.ea168b34632665267b72eb7818c6c3ad.jpg: 640x640 2 Fundacion Oranges, 9.2ms\n",
            "image 47/145 /content/Factoria-F5-3/test/images/Image_36_2_jpeg.rf.4f44c37aa60b29fd5ea2fbb3e0b8371a.jpg: 640x640 1 FemCoders, 9.7ms\n",
            "image 48/145 /content/Factoria-F5-3/test/images/Image_66_5_jpg.rf.35798f55817cd90bf40d057d97f87cfc.jpg: 640x640 1 Fundacion Orange, 10.8ms\n",
            "image 49/145 /content/Factoria-F5-3/test/images/Image_6_jpg.rf.e7a7df300cf29b942dba5a7f8b085ee6.jpg: 640x640 1 FemCoders, 1 SomosF5, 11.5ms\n",
            "image 50/145 /content/Factoria-F5-3/test/images/Tech-logos-The-most-famous-technology-company-logos-and-names_png.rf.80e9ec9f32c5adeb9e137ea8c99e6757.jpg: 640x640 1 Microsoft, 12.4ms\n",
            "image 51/145 /content/Factoria-F5-3/test/images/factoria-f5-memoria-2024_pdf_page_11_png.rf.978cee56efbc73e627032209df096990.jpg: 640x640 1 Factoria, 10.5ms\n",
            "image 52/145 /content/Factoria-F5-3/test/images/factoria-f5-memoria-2024_pdf_page_12_png.rf.756b5f2ae721a52c0c110b0aee27da83.jpg: 640x640 1 Factoria, 1 FemCoders, 9.1ms\n",
            "image 53/145 /content/Factoria-F5-3/test/images/factoria-f5-memoria-2024_pdf_page_17_png.rf.17f15f603731aad41a03cf667b8d7112.jpg: 640x640 1 Factoria, 30.2ms\n",
            "image 54/145 /content/Factoria-F5-3/test/images/factoria-f5-memoria-2024_pdf_page_4_png.rf.04d91a96253f018a52850b948a3e6a27.jpg: 640x640 1 Factoria, 9.8ms\n",
            "image 55/145 /content/Factoria-F5-3/test/images/fundacion_somos_f5_015_jpg.rf.b7c6867f13dc742a57cf01e7b0a45287.jpg: 640x640 1 SomosF5, 15.8ms\n",
            "image 56/145 /content/Factoria-F5-3/test/images/fundacion_somos_f5_069_jpg.rf.bb7b683681a24e3fbf8a7a6b57bd5e06.jpg: 640x640 (no detections), 24.0ms\n",
            "image 57/145 /content/Factoria-F5-3/test/images/fundacion_somos_f5_eventos_023_jpg.rf.d328830f9b3a02939f97bd3b960483f4.jpg: 640x640 1 SomosF5, 20.2ms\n",
            "image 58/145 /content/Factoria-F5-3/test/images/fundacion_somos_f5_eventos_056_jpg.rf.a5fd54a3603a9995a57c9d16ac0f5c5f.jpg: 640x640 (no detections), 8.5ms\n",
            "image 59/145 /content/Factoria-F5-3/test/images/img_0138_jpg.rf.4aab72305fd3c9b5a0c5e7ab7cb55931.jpg: 640x640 1 Microsoft, 31.5ms\n",
            "image 60/145 /content/Factoria-F5-3/test/images/img_0264_jpg.rf.2238cfdcdbe7bf56b7def4380031ff8e.jpg: 640x640 1 Microsoft, 29.5ms\n",
            "image 61/145 /content/Factoria-F5-3/test/images/img_0296_jpg.rf.f93b311c3f7042133cb6d96ea2efe13e.jpg: 640x640 2 Microsofts, 19.5ms\n",
            "image 62/145 /content/Factoria-F5-3/test/images/imgi_1012_316509111_681027536973572_80410437029247399_nfull_jpg.rf.f02812e5f89a356464e3810805bec1a3.jpg: 640x640 1 Factoria, 1 FemCoders, 10.4ms\n",
            "image 63/145 /content/Factoria-F5-3/test/images/imgi_1014_315495885_867722470914334_1410050083148682610_nfull_jpg.rf.ed8f44acc58ffaf2118cdd32d4a832ec.jpg: 640x640 (no detections), 9.2ms\n",
            "image 64/145 /content/Factoria-F5-3/test/images/imgi_1028_311889521_1256227808281778_4974054002443156464_nfull_jpg.rf.9c221d59b0dc6aee73ca61846da30a5a.jpg: 640x640 1 Factoria, 6.0ms\n",
            "image 65/145 /content/Factoria-F5-3/test/images/imgi_1034_311520801_634458981730916_704190155287657606_nfull_jpg.rf.ee01be38e15f103c381f8a2fafa77724.jpg: 640x640 1 Factoria, 1 FemCoders, 5.9ms\n",
            "image 66/145 /content/Factoria-F5-3/test/images/imgi_105_503480700_18318217033232883_7802189771224676264_nlow_jpg.rf.a04b2e15936e6c661e73334b198a3f3d.jpg: 640x640 1 F5, 1 Factoria, 1 SomosF5, 5.9ms\n",
            "image 67/145 /content/Factoria-F5-3/test/images/imgi_107_502406952_18317467954232883_3520721567223177016_nlow_jpg.rf.362c30b4a0a9f62721c1589313b1f722.jpg: 640x640 1 Factoria, 5.9ms\n",
            "image 68/145 /content/Factoria-F5-3/test/images/imgi_110_503455939_18315552877232883_6951328349351676921_nlow_jpg.rf.3aee77556b076fba5c5aa015fe506f59.jpg: 640x640 1 Factoria, 1 Microsoft, 5.9ms\n",
            "image 69/145 /content/Factoria-F5-3/test/images/imgi_1124_275215072_354055926631354_1073524277434991566_nfull_jpg.rf.cf5d58a934549b412ee10d1d81574639.jpg: 640x640 1 Factoria, 5.9ms\n",
            "image 70/145 /content/Factoria-F5-3/test/images/imgi_1126_274842591_128688946356845_6478454833448578982_nfull_jpg.rf.bc1612501288ff0ec7b6a70eaf63f206.jpg: 640x640 1 Factoria, 6.4ms\n",
            "image 71/145 /content/Factoria-F5-3/test/images/imgi_1129_274081467_654302672689827_8451395809402799653_nfull_jpg.rf.8447d8fab29af795b777a4863bc62916.jpg: 640x640 1 Factoria, 6.0ms\n",
            "image 72/145 /content/Factoria-F5-3/test/images/imgi_1133_273808045_1975736445931351_7324694129279706022_nfull_jpg.rf.3df122bf6fdf94841b5fa94003d664fc.jpg: 640x640 1 Factoria, 5.9ms\n",
            "image 73/145 /content/Factoria-F5-3/test/images/imgi_1155_262163318_265701555602406_7029700845314620961_nfull_jpg.rf.3db210d87c9e03d86176d9c29d484280.jpg: 640x640 1 Factoria, 5.9ms\n",
            "image 74/145 /content/Factoria-F5-3/test/images/imgi_1163_244219589_269853131692141_1880962321318977805_nfull_jpg.rf.d321ee2f3a55b083e87339051678b974.jpg: 640x640 (no detections), 5.9ms\n",
            "image 75/145 /content/Factoria-F5-3/test/images/imgi_1166_240455075_1090582454809486_8491623200527696411_nfull_jpg.rf.ea892a18e600b7edd7ef2fcc7b20450e.jpg: 640x640 (no detections), 5.9ms\n",
            "image 76/145 /content/Factoria-F5-3/test/images/imgi_1169_210492707_245218010365396_6828209005359209055_nfull_jpg.rf.959f5bb5675baf41ba3f8f4babd35e43.jpg: 640x640 1 Factoria, 5.9ms\n",
            "image 77/145 /content/Factoria-F5-3/test/images/imgi_1175_191928699_217865343255700_5241043125702552427_nfull_jpg.rf.e037a30feb9a74276b0a59306ba1e18d.jpg: 640x640 (no detections), 6.2ms\n",
            "image 78/145 /content/Factoria-F5-3/test/images/imgi_1182_182356285_313001993535898_3344529960769290494_nfull_jpg.rf.d3116fc3b597f3dc39de294659dd8415.jpg: 640x640 (no detections), 5.9ms\n",
            "image 79/145 /content/Factoria-F5-3/test/images/imgi_126_488301691_18308686927232883_5150915550133103406_nfull_jpg.rf.54d7daa1a200b654e72c9b1cfffdbbd5.jpg: 640x640 15 Factorias, 5.9ms\n",
            "image 80/145 /content/Factoria-F5-3/test/images/imgi_137_485176077_18306705277232883_1113503100199401605_nlow_jpg.rf.9afe53e0793464e172a86f8f7c45d066.jpg: 640x640 1 Factoria, 1 SomosF5, 6.1ms\n",
            "image 81/145 /content/Factoria-F5-3/test/images/imgi_147_481038471_18303755476232883_3555111862362781924_nlow_jpg.rf.afb81cfd95637fc5a62cca794a0b593f.jpg: 640x640 (no detections), 8.2ms\n",
            "image 82/145 /content/Factoria-F5-3/test/images/imgi_156_475655212_1152115269830981_3414413388239489897_nlow_jpg.rf.2eabfbb0366b88a53537f4df1bbb857a.jpg: 640x640 (no detections), 5.8ms\n",
            "image 83/145 /content/Factoria-F5-3/test/images/imgi_161_472854925_606550815647369_7767156504485579281_nlow_jpg.rf.51bdadc2dbbd83ef03af1bf987f970b1.jpg: 640x640 (no detections), 5.9ms\n",
            "image 84/145 /content/Factoria-F5-3/test/images/imgi_164_472974733_1172538014327130_682286987450852574_nlow_jpg.rf.bc3219f311aa3e1e877ff291554ddbc4.jpg: 640x640 1 SomosF5, 5.8ms\n",
            "image 85/145 /content/Factoria-F5-3/test/images/imgi_167_472499341_1327510105365947_2888059249389020277_nlow_jpg.rf.1f84e4afca767f941081be46c5750cbd.jpg: 640x640 1 Factoria, 1 SomosF5, 5.9ms\n",
            "image 86/145 /content/Factoria-F5-3/test/images/imgi_169_472037318_1794324724714174_4674053203423211883_nlow_jpg.rf.e935651a931a4842dd66e001d43d91a8.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 87/145 /content/Factoria-F5-3/test/images/imgi_174_470915447_1126145365624825_678431104653548722_nlow_jpg.rf.df6fa91d13bcefa99339eb288a641334.jpg: 640x640 1 Factoria, 1 SomosF5, 9.1ms\n",
            "image 88/145 /content/Factoria-F5-3/test/images/imgi_179_470306710_1764617534370205_3345446460592851625_nlow_jpg.rf.0f7ba77fa2424e04d05497c2362a545b.jpg: 640x640 (no detections), 5.9ms\n",
            "image 89/145 /content/Factoria-F5-3/test/images/imgi_184_469139127_4009438882670718_47118409293394149_nlow_jpg.rf.5b40fe230331aa83f91366bae9c89df1.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 90/145 /content/Factoria-F5-3/test/images/imgi_202_461959030_859032785986158_4649315622524408235_nlow_jpg.rf.6572fe11dba2d626d1e95e8a4f87ba8f.jpg: 640x640 1 Factoria, 1 SomosF5, 5.8ms\n",
            "image 91/145 /content/Factoria-F5-3/test/images/imgi_206_461161165_564335752585003_2087788504255740810_nlow_jpg.rf.8ec1c7acc925e21aa24dfd47938e5ae5.jpg: 640x640 1 Microsoft, 5.8ms\n",
            "image 92/145 /content/Factoria-F5-3/test/images/imgi_213_456574242_876533963916354_886437281306714624_nlow_jpg.rf.a0f7d8938766e5a3580045b018be4b97.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 93/145 /content/Factoria-F5-3/test/images/imgi_220_451012122_988201736110871_1957640948479917184_nlow_jpg.rf.ba823d4256a8224db659302509a63e19.jpg: 640x640 1 Factoria, 1 SomosF5, 5.8ms\n",
            "image 94/145 /content/Factoria-F5-3/test/images/imgi_228_447756553_1455217855360910_4706015579108165194_nlow_jpg.rf.92d9370912d5e6f92727ee52bf6b6c4d.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 95/145 /content/Factoria-F5-3/test/images/imgi_329_316877063_1619763225125447_829660436087702643_n_jpg.rf.3a3e770f205f292cc8291d2b7ebf96d5.jpg: 640x640 1 Factoria, 9.1ms\n",
            "image 96/145 /content/Factoria-F5-3/test/images/imgi_330_316509111_681027536973572_80410437029247399_n_jpg.rf.304364192c85f0047bcda6eb26bafde4.jpg: 640x640 1 Factoria, 1 FemCoders, 7.7ms\n",
            "image 97/145 /content/Factoria-F5-3/test/images/imgi_354_305384143_1693979770989085_213177574945462991_n_jpg.rf.89c89c9e99939a8826f6f07e3b476e29.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 98/145 /content/Factoria-F5-3/test/images/imgi_359_301127899_526964152152903_5210561241554759652_n_jpg.rf.8c197b6ff22afefa8043c50e36307535.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 99/145 /content/Factoria-F5-3/test/images/imgi_365_297548457_793755051979690_5360889747994501725_n_jpg.rf.9345d1064b99d25ffe13f89f67742765.jpg: 640x640 1 Factoria, 6.1ms\n",
            "image 100/145 /content/Factoria-F5-3/test/images/imgi_367_297584952_130049646402018_8662587345253658105_n_jpg.rf.de169dec6dc50da793997ff54f5462df.jpg: 640x640 1 Factoria, 1 FemCoders, 5.8ms\n",
            "image 101/145 /content/Factoria-F5-3/test/images/imgi_372_295381369_761672884980038_6806600527349313715_n_jpg.rf.03f183fba11218027fabcbf278d79bb9.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 102/145 /content/Factoria-F5-3/test/images/imgi_374_295051191_735951204288447_9074871630620157746_n_jpg.rf.3bbfdae2977d795560838626baa01dc8.jpg: 640x640 1 Factoria, 5.9ms\n",
            "image 103/145 /content/Factoria-F5-3/test/images/imgi_376_293319456_583699743127687_289311450425898270_n_jpg.rf.bcf84b2f308a5db47240c7f798bd0136.jpg: 640x640 1 Factoria, 7.7ms\n",
            "image 104/145 /content/Factoria-F5-3/test/images/imgi_385_290452117_1723494477995551_516074023307250063_n_jpg.rf.4941a7eb44a52cab3f674e7283abdae4.jpg: 640x640 1 Factoria, 6.1ms\n",
            "image 105/145 /content/Factoria-F5-3/test/images/imgi_401_280100654_540780214059705_617747547378463827_n_jpg.rf.d582804fdc103480942873208f200312.jpg: 640x640 1 Factoria, 6.0ms\n",
            "image 106/145 /content/Factoria-F5-3/test/images/imgi_406_279448469_323186743175552_3348819580377726795_n_jpg.rf.4e89e180521c5c250ec65076e5fe5248.jpg: 640x640 (no detections), 5.9ms\n",
            "image 107/145 /content/Factoria-F5-3/test/images/imgi_407_279057984_411540420356626_3304953098617966608_n_jpg.rf.962fd8cfd07003ca52bec06492b18480.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 108/145 /content/Factoria-F5-3/test/images/imgi_410_278954522_151030524076843_2052779024921283458_n_jpg.rf.6b1cc85ee7a4e922c67355167340f9fe.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 109/145 /content/Factoria-F5-3/test/images/imgi_430_275215072_354055926631354_1073524277434991566_nlow_jpg.rf.d1f78477f58136e5b9584d2ef6ef7843.jpg: 640x640 1 Factoria, 5.9ms\n",
            "image 110/145 /content/Factoria-F5-3/test/images/imgi_431_274990254_487556042811133_1968289975126193434_nlow_jpg.rf.7d1d5c7890693be5128f262a5f2030fe.jpg: 640x640 1 Factoria, 1 FemCoders, 5.8ms\n",
            "image 111/145 /content/Factoria-F5-3/test/images/imgi_441_273135577_1844123042643347_347383523773222877_nlow_jpg.rf.c87e549510c63c8f1858fcea70b4eb71.jpg: 640x640 1 Factoria, 6.7ms\n",
            "image 112/145 /content/Factoria-F5-3/test/images/imgi_443_272737724_2515415465259681_5374347690133207125_nlow_jpg.rf.71a00f9ce3cf837d845c408f4c575b80.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 113/145 /content/Factoria-F5-3/test/images/imgi_464_260839307_1244130669388939_9123385577629482844_nlow_jpg.rf.58ff720a16817e9fe4ec16012cd00ab0.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 114/145 /content/Factoria-F5-3/test/images/imgi_469_244349960_1513180449015167_7282815654694183957_nfull_jpg.rf.5bb48e0c60fab657a566dbc97547eba7.jpg: 640x640 (no detections), 5.8ms\n",
            "image 115/145 /content/Factoria-F5-3/test/images/imgi_477_210492707_245218010365396_6828209005359209055_nlow_jpg.rf.4c8b60b47fe311e9f9c831b3ab27cb5d.jpg: 640x640 1 Factoria, 5.8ms\n",
            "image 116/145 /content/Factoria-F5-3/test/images/imgi_575_75576674_782724218817685_7715325706603293576_n_jpg.rf.0af6021738e5215b369eaf55b43ef06a.jpg: 640x640 (no detections), 5.8ms\n",
            "image 117/145 /content/Factoria-F5-3/test/images/imgi_690_UNIVERSIDAD-DE-OVIEDO-logo-200x61_png.rf.3bf6e1b401ff643cad6eace1a08e0988.jpg: 640x640 1 Microsoft, 5.8ms\n",
            "image 118/145 /content/Factoria-F5-3/test/images/imgi_742_Microsoft-logo_rgb_c-gray-1200x538_png.rf.8559ab81e43c4be48d9c739d2a11d38d.jpg: 640x640 1 Microsoft, 7.2ms\n",
            "image 119/145 /content/Factoria-F5-3/test/images/imgi_793_538996992_18325053649232883_9100007406616541747_nfull_jpg.rf.f17eba884891198bae604d0f6442bb2d.jpg: 640x640 1 Factoria, 7.1ms\n",
            "image 120/145 /content/Factoria-F5-3/test/images/imgi_803_510504112_18318257446232883_941663314901730568_nfull_jpg.rf.59c841fef24ca09b1a1ca38b491b40e5.jpg: 640x640 (no detections), 6.4ms\n",
            "image 121/145 /content/Factoria-F5-3/test/images/imgi_809_503318427_18315456409232883_3225815139118393963_nfull_jpg.rf.3b7ac631238bb320e13bff990e666da5.jpg: 640x640 1 Factoria, 5.7ms\n",
            "image 122/145 /content/Factoria-F5-3/test/images/imgi_813_496963026_18312914920232883_7546115533260850249_nfull_jpg.rf.f9d8d2ed9986b1d0ad719677f43c513d.jpg: 640x640 (no detections), 5.7ms\n",
            "image 123/145 /content/Factoria-F5-3/test/images/imgi_823_488247938_18308594800232883_3469451479859032776_nfull_jpg.rf.69a1859a7dc0228351135ca7bfc55ccd.jpg: 640x640 1 Factoria, 1 SomosF5, 5.7ms\n",
            "image 124/145 /content/Factoria-F5-3/test/images/imgi_825_487096544_18308255401232883_7097456613776758299_nfull_jpg.rf.6e2b40a499320bd61284a8a1a1ed0d75.jpg: 640x640 1 F5, 1 FemCoders, 5.9ms\n",
            "image 125/145 /content/Factoria-F5-3/test/images/imgi_826_487422728_18308030302232883_7522529741631667002_nfull_jpg.rf.3b867fdc4181dfdcdfca318dd86312fe.jpg: 640x640 (no detections), 5.7ms\n",
            "image 126/145 /content/Factoria-F5-3/test/images/imgi_830_485211314_18307106674232883_3563413787110019278_nfull_jpg.rf.920187eabe9cdade62a91a993ad1a933.jpg: 640x640 1 Factoria, 5.7ms\n",
            "image 127/145 /content/Factoria-F5-3/test/images/imgi_832_484495291_18306815986232883_4398568000479346186_nfull_jpg.rf.77a0e354fa7ef465b4c44ad9ee900570.jpg: 640x640 (no detections), 5.7ms\n",
            "image 128/145 /content/Factoria-F5-3/test/images/imgi_840_482123006_619639064175333_3565646929180743590_nfull_jpg.rf.b055e6362d43fb863a58f0420d75ecdf.jpg: 640x640 (no detections), 5.7ms\n",
            "image 129/145 /content/Factoria-F5-3/test/images/imgi_841_481563150_18304378288232883_8339151489143231604_nfull_jpg.rf.12b16ab0bb28bdf962d414f64b1b3183.jpg: 640x640 1 Factoria, 5.7ms\n",
            "image 130/145 /content/Factoria-F5-3/test/images/imgi_842_481852016_18304138636232883_7081608118316049360_nfull_jpg.rf.53e8d4be426929618f62a1ea5d030ea5.jpg: 640x640 1 Factoria, 1 FemCoders, 1 SomosF5, 5.7ms\n",
            "image 131/145 /content/Factoria-F5-3/test/images/imgi_846_472655080_18302772241232883_7155369047966745935_nfull_jpg.rf.5fd4a0bccd5988074d4ae1fc27c3d987.jpg: 640x640 (no detections), 5.7ms\n",
            "image 132/145 /content/Factoria-F5-3/test/images/imgi_850_475655212_1152115269830981_3414413388239489897_nfull_jpg.rf.7bd5c2fdb5b20293290fdbfa9e98bdd0.jpg: 640x640 (no detections), 5.5ms\n",
            "image 133/145 /content/Factoria-F5-3/test/images/imgi_858_472974733_1172538014327130_682286987450852574_nfull_jpg.rf.67b613dd9d9fe34916ff533b9dc3c0e1.jpg: 640x640 1 SomosF5, 5.5ms\n",
            "image 134/145 /content/Factoria-F5-3/test/images/imgi_867_470915447_1126145365624825_678431104653548722_nfull_jpg.rf.f35ec0403d72fd327f3b62e302993de1.jpg: 640x640 1 Factoria, 1 SomosF5, 5.5ms\n",
            "image 135/145 /content/Factoria-F5-3/test/images/imgi_869_470944737_1609821433246036_3087107545108033838_nfull_jpg.rf.7ab78f3fb4091e138f9e0bc9fa07fd7a.jpg: 640x640 1 Factoria, 1 SomosF5, 5.5ms\n",
            "image 136/145 /content/Factoria-F5-3/test/images/imgi_888_463020685_1046503736958224_2369057912542711681_nfull_jpg.rf.05d9fe81f294a2285b42e0f113c45537.jpg: 640x640 1 Factoria, 1 SomosF5, 5.5ms\n",
            "image 137/145 /content/Factoria-F5-3/test/images/imgi_894_461798031_1708754013289160_4132798202906872928_nfull_jpg.rf.d2965b6ed043ac2e567c67d22a7bf134.jpg: 640x640 1 Factoria, 1 SomosF5, 6.4ms\n",
            "image 138/145 /content/Factoria-F5-3/test/images/imgi_899_459145084_443733448817402_2156067923626981646_nfull_jpg.rf.329e232acaf7259b0ab4fd38bf40086e.jpg: 640x640 1 Factoria, 1 FemCoders, 5.5ms\n",
            "image 139/145 /content/Factoria-F5-3/test/images/imgi_901_457275648_3277562962378373_8492638238746533975_nfull_jpg.rf.479056a5a3f5a9711b4f345818f7d5db.jpg: 640x640 1 Factoria, 6.3ms\n",
            "image 140/145 /content/Factoria-F5-3/test/images/imgi_902_456574242_876533963916354_886437281306714624_nfull_jpg.rf.2f2d3d095dc2ee6beea30a8506863f34.jpg: 640x640 1 Factoria, 5.5ms\n",
            "image 141/145 /content/Factoria-F5-3/test/images/imgi_903_453962423_484893044286430_8141723957635858430_nfull_jpg.rf.25b7570102d102ebca9b4b92e8d77e1c.jpg: 640x640 (no detections), 5.6ms\n",
            "image 142/145 /content/Factoria-F5-3/test/images/imgi_904_454150627_1250745952756499_2360860751491753315_nfull_jpg.rf.bb1ae931dfe777927dce715efeb2a7b2.jpg: 640x640 1 Factoria, 1 SomosF5, 5.5ms\n",
            "image 143/145 /content/Factoria-F5-3/test/images/imgi_905_453872197_485752040886862_8596266752793794518_nfull_jpg.rf.8c6ecd8040ef34cc4dc40dfb8e7b2766.jpg: 640x640 (no detections), 5.5ms\n",
            "image 144/145 /content/Factoria-F5-3/test/images/imgi_906_452778407_1191734831863260_7016171217026563437_nfull_jpg.rf.c9969e38d3b7b402e730ba4c25f30a32.jpg: 640x640 1 Factoria, 1 SomosF5, 5.5ms\n",
            "image 145/145 /content/Factoria-F5-3/test/images/imgi_907_452463070_424273807278730_1798517254396529498_nfull_jpg.rf.d3965f98d5ea5907f9ec3cbab7440240.jpg: 640x640 1 SomosF5, 5.5ms\n",
            "Speed: 2.7ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/predict/factoria_f5_demo\u001b[0m\n",
            "Resultados guardados en: runs/predict/factoria_f5_demo\n"
          ]
        }
      ]
    }
  ]
}